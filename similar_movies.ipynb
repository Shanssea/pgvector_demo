{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring pgvector Capabilities </br>\n",
    "\n",
    "We will explore pgvector capabilities using two use cases. First, we will try to understand each indexing method and distance function used in pgvector. Then we will try to  create a semantic similarity search using  pgvector, Langchain, and GeminiAI using dataset from <a link=\"https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots\">Kaggle</a>.\n",
    "\n",
    "Before we do anything, we need to prepare our database. <i>Please refer to the [README](./README.md) file</i></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring pgvector Distance Function\n",
    "Before we jump to the real use case, we need to understand distance function in pgvector. Based on pgvector official documentation, there are four distance function supported in pgvector.\n",
    "- `<->` - L2 Distance (Euclidean)\n",
    "- `<=>` - Cosine Distance\n",
    "- `<#>` - (Negative) Inner Product\n",
    "- `<+>` - L1 Distance (added in ver. 0.7.0)\n",
    "\n",
    "Let's discuss one by one!\n",
    "\n",
    "#### Understanding Each Distance Function in pgvector\n",
    "1.  `<->` - L2 Distance (Euclidean)</br>\n",
    "L2 Distance or Euclidean distance measure distance between 2 points. It is sensitive to vector magnitude and orientation. In Natural Language Processing (NLP) similarity is often measured by orientation rather than magnitude. You can prefer to use Euclidean distance when magnitude plays a part to determined the similarity of objects. The code below visualize two vectors that have similar semantic (pointing to the same direction) but have different magnitude. The space between each points is quite far right?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example vectors. Both are pointing to the same direction (semantically similar), but have different magnitude.\n",
    "# Vector A: (3, 3)\n",
    "# Vector B: (6, 8)\n",
    "\n",
    "a = np.array((3,3))\n",
    "b = np.array((6,8))\n",
    "\n",
    "V = np.array([a, b])\n",
    "origin = np.array([[0, 0],[0, 0]]) # origin point\n",
    "\n",
    "# set max x and y\n",
    "plt.xlim(-max(V[:, 0]) - 1, max(V[:, 0]) + 1)\n",
    "plt.ylim(-max(V[:, 1]) - 1, max(V[:, 1]) + 1)\n",
    "\n",
    "plt.quiver(*origin, V[:,0], V[:,1], color=['r','b'], scale=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `<=>` - Cosine Distance </br>\n",
    "Cosine distance measure the angle or orientation between vectors. Magnitude is not measured when using cosine, which can be beneficial when searching objects that have different length such as documents and title. \n",
    "\n",
    "3. `<#>` - (Negative) Inner Product </br>\n",
    "Inner product measure the projected vector to another vector. It is sensitive for both orientation and magnitude. If inner product is normalize, it is the same as cosine distance. \n",
    "\n",
    "4. `<+>` - L1 Distance (added in ver. 0.7.0)\n",
    "L2 and L1 distance is similar, both calculate distance between two points. The different is L1 measure distance using grid like path. L1 distance is more sensitive to orientation and magnitude than L2. You can use L1 distance when you want to see the absolute different between two points. L1 Distance is more sensitive to outlier than other function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 Distance:  5.830951894845301\n",
      "Cosine Distance:  0.9899494936611667\n",
      "Inner Product:  42\n",
      "L1 Distance:  8.0\n"
     ]
    }
   ],
   "source": [
    "# L2 Distance / Euclidean Distance\n",
    "# Smallest number (nearest distance), means it is more similar\n",
    "l2_dist = np.linalg.norm(a-b)\n",
    "print(\"L2 Distance: \", l2_dist)\n",
    "\n",
    "# Cosine Distance\n",
    "# Result with closer to zero means it is more similar\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "cosine = dot(a, b)/(norm(a)*norm(b))\n",
    "print(\"Cosine Distance: \", cosine)\n",
    "\n",
    "# Inner Product\n",
    "# Larger result means it is more similar\n",
    "inner = np.inner(a, b)\n",
    "print(\"Inner Product: \", inner)\n",
    "\n",
    "# L1 Distance\n",
    "# Smallest number (nearest distance), means it is more similar\n",
    "l1_dist = np.linalg.norm(a-b, ord=1)\n",
    "print(\"L1 Distance: \", l1_dist)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring pgvector Index Function\n",
    "We already understand of each distance function in pgvector. These function won't be useful if query time is still slow. To fasten the query time, we can apply indexing function to the table. This wil prevent full table scan.\n",
    "\n",
    "From [pgvector documentation](https://github.com/pgvector/pgvector), by default pgvector will perform exact nearest neighbor search which return perfect recall. In other words, a full table scan, which significantly increases query execution time.\n",
    "\n",
    "There are two indexing method in pgvector. IVFFlat and HNSW. <b>IVFFlat</b> or the Inverted File with Flat Compression will create clusters of vectors. When searching for similar vectors of the input, pgvector will search for the nearest centroid of the cluster then look into the cluster’s member. It has faster build time and uses less memory than HNSW, but has lower query performance.\n",
    "\n",
    "<b>HNSW</b> or Hierarchical Navigable Small Worlds use a different approach of indexing vector data. Instead of creating clusters, pgvector will create layers of dense linked vectors. When searching for similar vectors of the input, pgvector will search the nearest vector on the top layer. Then it will descend and search for the nearest vectors on that layer, repeat until it generate the closest vector. \n",
    "\n",
    "We will use [dataset loaded from Hugging Face]((https://huggingface.co/datasets/Cohere/wikipedia-22-12-simple-embeddings)). This dataset contains about 485,859 article with generated vectors. We will use this dataset when comparing index function in PgVector.\n",
    "\n",
    "Let's load the dataset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset # HuggingFace dataset library\n",
    "\n",
    "# Import hugging face dataset as dataframe\n",
    "dataset = load_dataset(\"Cohere/wikipedia-22-12-simple-embeddings\", split=\"train\")\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "print(df.iloc[:5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# I use .env file to store my credentials\n",
    "load_dotenv()\n",
    "PASSWORD = os.getenv(\"PASSWORD\")\n",
    "FILE_PATH = \"./dataset/vector_database_wikipedia_articles_embedded.csv\"\n",
    "\n",
    "# Adjust accordingly\n",
    "conn_string = f'postgresql://postgres:{PASSWORD}@localhost:5432/pgvector_sandbox'\n",
    "\n",
    "# Create db connection\n",
    "db = create_engine(conn_string) \n",
    "\n",
    "with psycopg2.connect(conn_string) as conn:\n",
    "    conn.autocommit = True\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    query='''\n",
    "        -- CAUTION!! you will delete all data in this table. Proceed with caution.\n",
    "        DROP TABLE wiki_article;\n",
    "\n",
    "        CREATE TABLE wiki_article (\n",
    "            id INTEGER NOT NULL,\n",
    "            title TEXT,\n",
    "            text TEXT,\n",
    "            url TEXT,\n",
    "            wiki_id INTEGER,\n",
    "            views FLOAT,\n",
    "            paragraph_id INTEGER,\n",
    "            langs INTEGER,\n",
    "            emb VECTOR(768)\n",
    "        );\n",
    "    '''\n",
    "    cursor.execute(query) \n",
    "\n",
    "# Insert to db\n",
    "with db.connect() as conn:\n",
    "    df.to_sql('wiki_article', con=conn, if_exists='append', index=False)\n",
    "\n",
    "# Get data from db \n",
    "with psycopg2.connect(conn_string) as conn:\n",
    "    conn.autocommit = True\n",
    "    cursor = conn.cursor() \n",
    "\n",
    "    query = '''\n",
    "        SELECT * FROM wiki_article LIMIT 10; \n",
    "\n",
    "    '''\n",
    "    cursor.execute(query) \n",
    "    \n",
    "    # Show data\n",
    "    for i in cursor.fetchall(): \n",
    "        print(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to create the index. </br>\n",
    "\n",
    "First let's try creating <b>IVFflat</b> index. </br>\n",
    "Based on the official documentation, there are three keys to achieving good recall using IVFFlat index:\n",
    "1. Create the index after the table has some data.\n",
    "2. Choose an appropiate number of lists. Recommended to start with `rows / 1000` for up to 1M rows and `sqrt(rows)` for over 1M rows.\n",
    "3. Sepcify an appropiate number of probes. example: `SET ivfflat.probes = 10;`. A higher value provides better recall at the cost of speed. \n",
    "\n",
    "We already populate the table with a 35000 rows data. It is small compared to the real world production data, but we still can compare the different between indexing method using this.\n",
    "\n",
    "Before we start, we need to generate vector embedding from our input string. We will use [GeminiAI with Text Embedding 004 model](https://ai.google.dev/gemini-api/docs/embeddings) to create this.\n",
    "We want to find the top 10 most famous articles about computer history. This is our prompt:\n",
    "> Find me top 10 most famous articles about computer history\n",
    "\n",
    "To create vector embedding, we need to use model. Let's try using Gemini API.\n",
    "You need to sign in to <a link=\"https://aistudio.google.com/\">Google AI Studio</a> first, and get the Gemini API key. Currently, Gemini API is free of charge with some limitation. You can find more information about this <a link=\"https://ai.google.dev/pricing\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.033782307, 0.031816702, -0.026316019, 0.009792 ... TRIMMED]\n",
      "768\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "prompt = \"Find me 10 articles about computer history\"\n",
    "\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "prompt_embed = genai.embed_content(\n",
    "    model=\"models/text-embedding-004\",\n",
    "    content=prompt,\n",
    "    task_type=\"semantic_similarity\",\n",
    "    \n",
    ")\n",
    "\n",
    "print(str(prompt_embed['embedding'])[:50], '... TRIMMED]') # Show some part of the vector\n",
    "print(len(prompt_embed['embedding'])) # Show dimension size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do semantic similarity search from the input to the nearest article. We will also start the timer to show how long the searching last.\n",
    "We didn't apply any indexing method yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing similarity search with cosine distance function with no index\n"
     ]
    },
    {
     "ename": "UndefinedFunction",
     "evalue": "operator does not exist: text <=> vector\nLINE 7:             content_vector <=> ve similarity -- we use cosin...\n                                   ^\nHINT:  No operator matches the given name and argument types. You might need to add explicit type casts.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUndefinedFunction\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# marks the start of the execution\u001b[39;00m\n\u001b[1;32m     21\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 22\u001b[0m \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m seconds ---\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time))\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Show data\u001b[39;00m\n",
      "\u001b[0;31mUndefinedFunction\u001b[0m: operator does not exist: text <=> vector\nLINE 7:             content_vector <=> ve similarity -- we use cosin...\n                                   ^\nHINT:  No operator matches the given name and argument types. You might need to add explicit type casts.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "print(\"Executing similarity search with cosine distance function with no index\")\n",
    "\n",
    "# Get data from db\n",
    "with psycopg2.connect(conn_string) as conn:\n",
    "    conn.autocommit = True\n",
    "    cursor = conn.cursor() \n",
    "\n",
    "    query = f'''\n",
    "        WITH input AS (\n",
    "            SELECT '{prompt_embed[\"embedding\"]}'::VECTOR(768) AS ve\n",
    "        )\n",
    "        SELECT \n",
    "            title,\n",
    "            content_vector <=> ve similarity -- we use cosine similarity\n",
    "        FROM wiki_article join input on 1=1\n",
    "        ORDER BY content_vector <=> ve\n",
    "        LIMIT 10; \n",
    "    '''\n",
    "    # marks the start of the execution\n",
    "    start_time = time.time()\n",
    "    cursor.execute(query)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    \n",
    "    # Show data\n",
    "    for i in cursor.fetchall(): \n",
    "        print(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands On: Semantic Similarity Search using pgvector, LangChain, and GeminiAI\n",
    "What we'll do in this hands on?\n",
    "1. Insert [Wikipedia movie plot](https://www.kaggle.com/datasets/jrobischon/wikipedia-movie-plots) dataset, retrieved from Kaggle by JustinR.\n",
    "2. Create vector embedding of the plot using LangChain and Gemini AI.\n",
    "3. Determine indexing method and distance function\n",
    "4. Create function to retrieve user input then generate it's vector embedding.\n",
    "5. Search similarity between user input and movies.\n",
    "\n",
    "Let's insert the data first!\n",
    "The code is the same as inserting Wikipedia article to the database when we try to explore indexing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Import csv file as dataframe\u001b[39;00m\n\u001b[1;32m      5\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFILE_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(file_path)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Insert to db\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m db\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;28;01mas\u001b[39;00m conn:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# different source dataset\n",
    "FILE_PATH = \"./dataset/wiki_movie_plots_deduped.csv\"\n",
    "\n",
    "# Import csv file as dataframe\n",
    "file_path = f\"{FILE_PATH}\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Insert to db\n",
    "with db.connect() as conn:\n",
    "    df.to_sql('movies_plot', con=conn, if_exists='replace', index=False)\n",
    "\n",
    "# Get data from db \n",
    "with psycopg2.connect(conn_string) as conn:\n",
    "    conn.autocommit = True\n",
    "    cursor = conn.cursor() \n",
    "\n",
    "    query = '''\n",
    "        -- Create ID set as primary key\n",
    "        ALTER TABLE movies_plot\n",
    "        ADD COLUMN movie_id INTEGER PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY;\n",
    "\n",
    "        SELECT * FROM movies_plot LIMIT 10; \n",
    "\n",
    "    '''\n",
    "    cursor.execute(query) \n",
    "    \n",
    "    # Show data\n",
    "    for i in cursor.fetchall(): \n",
    "        print(i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to get the embedding of each data row. Before that, let's get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only generate vector embedding for movie's plot. The text is a bit long so we need to chunked it. We need to chunk long text into smaller chuck to match with the API request size limit. For demonstration, We will chunk our data with chunk size 500 token.\n",
    "\n",
    "Please notice at the moment, Gemini API free tier for model text embedding 004 has limit 1500 request per minutes. Our dataset has 35000 row, it is far over the limit. So we will only send about 1000 row to the API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\".\", \"\\n\"],\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=0,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    movie_id = row[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
